{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramadanzakbar/lihat-formasi/blob/main/document%20langraph%20memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_core langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfPlOGCdrWDy",
        "outputId": "9c681bc1-537a-4d71-f7f9-bbd9904fce1c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.11/dist-packages (0.3.68)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.5.3-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (0.4.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (4.14.1)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (2.11.7)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.6.0,>=0.5.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.5.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.73-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain_core) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain_core) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain_core) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain_core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain_core) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain_core) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.7.9)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain_core) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain_core) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.5.3-py3-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.5.2-py3-none-any.whl (23 kB)\n",
            "Downloading langgraph_sdk-0.1.73-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.5.3 langgraph-checkpoint-2.1.0 langgraph-prebuilt-0.5.2 langgraph-sdk-0.1.73 ormsgpack-1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fc34b74"
      },
      "source": [
        "from langchain_core.runnables import Runnable\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langchain.memory import ChatMessageHistory\n",
        "\n",
        "# Dummy LLM that returns static responses and acts as a Runnable\n",
        "class DummyLLM(Runnable):\n",
        "    def __init__(self, responses=None):\n",
        "        self.responses = responses or {\n",
        "            \"Hai\": \"Halo! Ada yang bisa saya bantu?\",\n",
        "            \"Apa kabar?\": \"Saya hanya program komputer, tapi saya baik-baik saja!\",\n",
        "            \"Siapa kamu?\": \"Saya adalah Dummy Chatbot yang dibuat untuk demonstrasi.\",\n",
        "            \"default\": \"Maaf, saya tidak mengerti pertanyaan Anda.\"\n",
        "        }\n",
        "\n",
        "    def invoke(self, prompt, config=None):\n",
        "        # Assuming the input is a HumanMessage\n",
        "        if isinstance(prompt, list) and prompt:\n",
        "            last_message = prompt[-1]\n",
        "            if isinstance(last_message, HumanMessage):\n",
        "                return AIMessage(content=self.responses.get(last_message.content.strip(), self.responses[\"default\"]))\n",
        "        # Fallback for unexpected input format\n",
        "        return AIMessage(content=self.responses[\"default\"])\n",
        "\n",
        "# Simpan riwayat percakapan berdasarkan session_id\n",
        "memory_store = {}\n",
        "\n",
        "def get_history(session_id: str) -> ChatMessageHistory:\n",
        "    if session_id not in memory_store:\n",
        "        memory_store[session_id] = ChatMessageHistory()\n",
        "    return memory_store[session_id]"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: tolong print contoh percakapannya\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "# Inisialisasi LLM dummy\n",
        "llm = DummyLLM()\n",
        "\n",
        "# Define the prompt template\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful AI assistant.\"),\n",
        "    MessagesPlaceholder(variable_name=\"history\"),\n",
        "    (\"human\", \"{input}\")\n",
        "])\n",
        "\n",
        "# Create the chain\n",
        "chain = prompt | llm\n",
        "\n",
        "# Buat runnable dengan history percakapan\n",
        "runnable_with_history = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    get_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"history\"\n",
        ")\n",
        "\n",
        "# Contoh percakapan\n",
        "session_id = \"user123\" # Contoh ID sesi\n",
        "config = {\"configurable\": {\"session_id\": session_id}}\n",
        "\n",
        "print(\"User: Hai\")\n",
        "response1 = runnable_with_history.invoke({\"input\": \"Hai\"}, config=config)\n",
        "print(f\"Bot: {response1.content}\")\n",
        "\n",
        "print(\"\\nUser: Apa kabar?\")\n",
        "response2 = runnable_with_history.invoke({\"input\": \"Apa kabar?\"}, config=config)\n",
        "print(f\"Bot: {response2.content}\")\n",
        "\n",
        "print(\"\\nUser: Siapa kamu?\")\n",
        "response3 = runnable_with_history.invoke({\"input\": \"Siapa kamu?\"}, config=config)\n",
        "print(f\"Bot: {response3.content}\")\n",
        "\n",
        "print(\"\\nUser: Siapa kamu?\")\n",
        "response4 = runnable_with_history.invoke({\"input\": \"Siapa kamu?\"}, config=config)\n",
        "print(f\"Bot: {response4.content}\")\n",
        "\n",
        "# Anda bisa memeriksa riwayat percakapan untuk sesi ini\n",
        "print(\"\\nRiwayat Percakapan:\")\n",
        "for message in get_history(session_id).messages:\n",
        "    print(f\"{type(message).__name__}: {message.content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrvV4PBx0bku",
        "outputId": "b2028ad5-24c7-408b-a1f6-efaa954c0006"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: Hai\n",
            "Bot: Maaf, saya tidak mengerti pertanyaan Anda.\n",
            "\n",
            "User: Apa kabar?\n",
            "Bot: Maaf, saya tidak mengerti pertanyaan Anda.\n",
            "\n",
            "User: Siapa kamu?\n",
            "Bot: Maaf, saya tidak mengerti pertanyaan Anda.\n",
            "\n",
            "User: Siapa kamu?\n",
            "Bot: Maaf, saya tidak mengerti pertanyaan Anda.\n",
            "\n",
            "Riwayat Percakapan:\n",
            "HumanMessage: Hai\n",
            "AIMessage: Maaf, saya tidak mengerti pertanyaan Anda.\n",
            "HumanMessage: Apa kabar?\n",
            "AIMessage: Maaf, saya tidak mengerti pertanyaan Anda.\n",
            "HumanMessage: Siapa kamu?\n",
            "AIMessage: Maaf, saya tidak mengerti pertanyaan Anda.\n",
            "HumanMessage: Ceritakan tentang cuaca hari ini.\n",
            "AIMessage: Maaf, saya tidak mengerti pertanyaan Anda.\n",
            "HumanMessage: Hai\n",
            "AIMessage: Maaf, saya tidak mengerti pertanyaan Anda.\n",
            "HumanMessage: Apa kabar?\n",
            "AIMessage: Maaf, saya tidak mengerti pertanyaan Anda.\n",
            "HumanMessage: Siapa kamu?\n",
            "AIMessage: Maaf, saya tidak mengerti pertanyaan Anda.\n",
            "HumanMessage: Ceritakan tentang cuaca hari ini.\n",
            "AIMessage: Maaf, saya tidak mengerti pertanyaan Anda.\n",
            "HumanMessage: Hai\n",
            "AIMessage: Maaf, saya tidak mengerti pertanyaan Anda.\n",
            "HumanMessage: Apa kabar?\n",
            "AIMessage: Maaf, saya tidak mengerti pertanyaan Anda.\n",
            "HumanMessage: Siapa kamu?\n",
            "AIMessage: Maaf, saya tidak mengerti pertanyaan Anda.\n",
            "HumanMessage: Siapa kamu?\n",
            "AIMessage: Maaf, saya tidak mengerti pertanyaan Anda.\n",
            "HumanMessage: Hai\n",
            "AIMessage: Maaf, saya tidak mengerti pertanyaan Anda.\n",
            "HumanMessage: Apa kabar?\n",
            "AIMessage: Maaf, saya tidak mengerti pertanyaan Anda.\n",
            "HumanMessage: Siapa kamu?\n",
            "AIMessage: Maaf, saya tidak mengerti pertanyaan Anda.\n",
            "HumanMessage: Siapa kamu?\n",
            "AIMessage: Maaf, saya tidak mengerti pertanyaan Anda.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, TypedDict, List\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# Definisikan state\n",
        "class ChatState(TypedDict):\n",
        "    messages: List[str]\n",
        "    turn_count: int\n",
        "\n",
        "# Buat node fungsi dummy\n",
        "def dummy_respond(state: ChatState) -> Dict[str, List[str]]:\n",
        "    last_message = state[\"messages\"][-1]\n",
        "\n",
        "    # Logika respons sederhana\n",
        "    if \"hai\" in last_message.lower():\n",
        "        response = \"Halo juga!\"\n",
        "    elif \"nama\" in last_message.lower():\n",
        "        response = \"Saya DummyBot\"\n",
        "    elif \"bye\" in last_message.lower():\n",
        "        response = \"Sampai jumpa!\"\n",
        "    else:\n",
        "        response = \"Saya tidak mengerti\"\n",
        "\n",
        "    return {\"messages\": [response], \"turn_count\": state[\"turn_count\"] + 1}\n",
        "\n",
        "# Buat workflow\n",
        "workflow = StateGraph(ChatState)\n",
        "\n",
        "# Tambahkan node\n",
        "workflow.add_node(\"dummy_bot\", dummy_respond)\n",
        "\n",
        "# Set entry point\n",
        "workflow.set_entry_point(\"dummy_bot\")\n",
        "\n",
        "# Tambahkan edge\n",
        "workflow.add_edge(\"dummy_bot\", END)\n",
        "\n",
        "# Compile graph\n",
        "app = workflow.compile()\n",
        "\n",
        "# Jalankan chat\n",
        "def run_chat():\n",
        "    state = {\"messages\": [], \"turn_count\": 0}\n",
        "    print(\"DummyBot: Halo! Ketik 'bye' untuk keluar.\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"Anda: \")\n",
        "        state[\"messages\"].append(user_input)\n",
        "\n",
        "        # Jalankan graph\n",
        "        result = app.invoke(state)\n",
        "        bot_response = result[\"messages\"][-1]\n",
        "        state = result\n",
        "\n",
        "        print(f\"DummyBot: {bot_response}\")\n",
        "\n",
        "        if \"bye\" in user_input.lower():\n",
        "            print(f\"Total percakapan: {state['turn_count']} putaran\")\n",
        "            break\n",
        "\n",
        "# Jalankan chat (di Colab mungkin perlu modifikasi untuk input)\n",
        "run_chat()\n",
        "\n",
        "# Untuk Colab, kita bisa simulasi:\n",
        "print(\"\\nSimulasi LangGraph:\")\n",
        "state = {\"messages\": [\"bye\"], \"turn_count\": 0}\n",
        "result = app.invoke(state)\n",
        "print(f\"Input: {state['messages'][0]}\")\n",
        "print(f\"Output: {result['messages'][0]}\")\n",
        "print(f\"Turn count: {result['turn_count']}\")"
      ],
      "metadata": {
        "id": "RceRxXz81upB",
        "outputId": "f998804a-eb48-4c82-f339-c1df35f8d308",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DummyBot: Halo! Ketik 'bye' untuk keluar.\n",
            "Anda: halo!\n",
            "DummyBot: Saya tidak mengerti\n",
            "Anda: oke\n",
            "DummyBot: Saya tidak mengerti\n",
            "Anda: Halo!\n",
            "DummyBot: Saya tidak mengerti\n",
            "Anda: bye\n",
            "DummyBot: Sampai jumpa!\n",
            "Total percakapan: 4 putaran\n",
            "\n",
            "Simulasi LangGraph:\n",
            "Input: bye\n",
            "Output: Sampai jumpa!\n",
            "Turn count: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import AIMessage, HumanMessage\n",
        "from langchain.memory import ChatMessageHistory\n",
        "\n",
        "# Buat memory chat\n",
        "history = ChatMessageHistory()\n",
        "\n",
        "# Dummy bot dengan memory\n",
        "class DummyChatbot:\n",
        "    def __init__(self, history):\n",
        "        self.history = history\n",
        "        self.responses = {\n",
        "            \"hi\": \"Hello! How can I help you today?\",\n",
        "            \"how are you\": \"I'm just a program, but I'm functioning well!\",\n",
        "            \"what's your name\": \"I'm DummyBot with memory!\",\n",
        "            \"default\": \"I don't understand. Can you rephrase?\"\n",
        "        }\n",
        "\n",
        "    def respond(self, user_input):\n",
        "        # Tambahkan pesan user ke history\n",
        "        self.history.add_user_message(user_input)\n",
        "\n",
        "        # Cari respons\n",
        "        input_lower = user_input.lower()\n",
        "        response = next(\n",
        "            (v for k, v in self.responses.items() if k in input_lower),\n",
        "            self.responses[\"default\"]\n",
        "        )\n",
        "\n",
        "        # Tambahkan respons bot ke history\n",
        "        self.history.add_ai_message(response)\n",
        "        return response\n",
        "\n",
        "# Inisialisasi chatbot\n",
        "bot = DummyChatbot(history)\n",
        "\n",
        "# Simulasi percakapan\n",
        "print(\"Bot:\", bot.respond(\"Hi\"))\n",
        "print(\"Bot:\", bot.respond(\"What's your name?\"))\n",
        "print(\"Bot:\", bot.respond(\"Tell me a joke\"))\n",
        "print(\"Bot:\", bot.respond(\"How are you?\"))\n",
        "\n",
        "# Lihat history\n",
        "print(\"\\nChat History:\")\n",
        "for msg in history.messages:\n",
        "    if isinstance(msg, HumanMessage):\n",
        "        print(f\"User: {msg.content}\")\n",
        "    else:\n",
        "        print(f\"Bot: {msg.content}\")"
      ],
      "metadata": {
        "id": "mPgPzPD11j9l",
        "outputId": "027894f9-aaae-4363-83de-531b3f91d012",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bot: Hello! How can I help you today?\n",
            "Bot: I'm DummyBot with memory!\n",
            "Bot: I don't understand. Can you rephrase?\n",
            "Bot: I'm just a program, but I'm functioning well!\n",
            "\n",
            "Chat History:\n",
            "User: Hi\n",
            "Bot: Hello! How can I help you today?\n",
            "User: What's your name?\n",
            "Bot: I'm DummyBot with memory!\n",
            "User: Tell me a joke\n",
            "Bot: I don't understand. Can you rephrase?\n",
            "User: How are you?\n",
            "Bot: I'm just a program, but I'm functioning well!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7w2_0dTk5Cpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ChatMessageHistory\n",
        "\n",
        "history = ChatMessageHistory()\n",
        "history.add_user_message(\"Halo!\")\n",
        "history.add_ai_message(\"Hai, ada yang bisa saya bantu?\")\n",
        "history.add_user_message(\"apa kabarnya\")\n",
        "history.add_ai_message(\"baik\")\n",
        "print(history.messages)"
      ],
      "metadata": {
        "id": "RhZnRQSt5DaC",
        "outputId": "b3e9843e-b59b-4d69-a817-789ff6aba785",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HumanMessage(content='Halo!', additional_kwargs={}, response_metadata={}), AIMessage(content='Hai, ada yang bisa saya bantu?', additional_kwargs={}, response_metadata={}), HumanMessage(content='apa kabarnya', additional_kwargs={}, response_metadata={}), AIMessage(content='baik', additional_kwargs={}, response_metadata={})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "memory.save_context({\"input\": \"Halo!\"}, {\"output\": \"Hai, ada yang bisa saya bantu?\"})\n",
        "print(memory.load_memory_variables({}))\n",
        "memory"
      ],
      "metadata": {
        "id": "sS_Te27N5LX0",
        "outputId": "049cd2aa-2a7c-459a-cc80-07dbceb5dab4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'history': 'Human: Halo!\\nAI: Hai, ada yang bisa saya bantu?'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Halo!', additional_kwargs={}, response_metadata={}), AIMessage(content='Hai, ada yang bisa saya bantu?', additional_kwargs={}, response_metadata={})]))"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}